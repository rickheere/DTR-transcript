undefined
00:04 [Music]
00:21 [Music]
00:29 welcome back to deep thoughts ladies and
00:31 gentlemen it's another night episode
00:35 doing quite a few of these this season
00:37 to probably change today we're gonna
00:40 talk about a subject that I've been
00:41 mentioning quite a bit that's getting
00:43 mentioned a lot in the press it's
00:44 getting mentioned a lot in television
00:45 shows and movies and just friends of
00:48 mine obviously most of them are not
00:52 engineers and so they're talking about
00:54 it's you know sort of in a fearful way
00:57 and sort of in a excited way much less
01:00 on the excited side by friends who are
01:04 really my mentors in coding are posting
01:09 online in their social media you know
01:11 the lunacy that is going around about
01:13 where we are with artificial
01:14 intelligence and where it's going to be
01:16 and what we're going to be capable of
01:17 doing which is my sentiment but what's
01:21 strange about artificial intelligence is
01:23 we have you know like religion when you
01:29 learn a religion it's sort of a
01:31 comforting you know it's mostly
01:33 comforting right it's a way to live your
01:34 life it's a way to be successful with
01:37 other people with your own soul and then
01:40 of course there are the the punishments
01:42 that go along with religions which is
01:44 because they're geared towards making
01:46 society function and mature and become a
01:49 society as opposed to law of the jungle
01:52 that's what the ten commandments do like
01:54 stop doing this you can't just kill
01:56 everybody can you imagine the world
01:58 before they told us not to kill each
01:59 other that that was a sin of some sort I
02:03 don't even know people I don't know if
02:06 people you know sixty thousand years ago
02:10 thought it was terribly horrible we have
02:12 cannibals in South America and Africa
02:15 who believe that eating the people that
02:18 they killed was a not only an honorable
02:21 thing but they assumed the spiritual
02:24 resilience of the people they ate so I
02:28 don't know I don't know where that is
02:29 but AI is growing in a really strange
02:34 way it is almost either loathe
02:38 for its ability to you know shadow band
02:42 and sensor or it's feared because it is
02:46 getting into this massive transhumanism
02:49 arc which is really strange because I
02:53 should say the word transhumanism is
02:56 strange I didn't episode on a long time
02:57 ago it's something that's occurring
03:00 slowly and no one's really using the
03:04 word enough people need to say the word
03:06 more because it is what's going on you
03:08 need to understand that's what's going
03:11 on now the biggest movement on planet
03:16 Earth for artificial intelligence above
03:19 ground ok as reycarts well who is a
03:22 scientist he is in charge of his group
03:27 called the singularity project which is
03:29 in Mountain View California as I
03:31 understand it on the Google campus
03:32 financed by one of the cofounders of
03:34 Google yes we know that that
03:37 organization is potentially a fictitious
03:41 construct created by other individuals
03:45 and organizations and you probably be
03:48 right but that's not really important at
03:51 this stage in this conversation but his
03:55 fantasy has been to digitize his
03:58 consciousness and live in a computer for
04:00 the rest of his life he wants to be
04:01 immortal what's interesting about it is
04:04 that he wants to be the first one to use
04:06 the technology I think and you know I
04:10 was involved with the science-fiction
04:11 script that was stolen and became
04:16 transcendence and both films had the
04:20 same because they stole ours a person
04:24 was able to accomplish this in the
04:26 script and they were the first person to
04:28 throw themselves into it and they ended
04:30 up a really weird mmm kind of a bad
04:35 artificial intelligence in the basement
04:39 now in transcendence they switched it
04:41 such that it was Johnny Depp's character
04:43 and he eventually became very wise and
04:45 our script it was the father of the
04:47 character that was Johnny Depp's
04:49 character and it was a daughter
04:52 she went off and was very successful our
04:54 script Johnny the writers who took it
04:57 made it both the father and the daughter
05:01 they just kept the arc going whatever
05:04 when you write a film like that and work
05:06 on a film like that you are studying the
05:08 living crap out of what's possible you
05:11 have crazy conversations about how to
05:14 you know I was involved in a
05:16 conversation where the writer is fairly
05:18 technical but he was like dude we need
05:21 to make like a theory we're a hard drive
05:23 type storage device could be sort of at
05:26 an atomic quantum level how would we do
05:28 that and I was just you know I was using
05:31 you know it that the position of it was
05:35 electron orbits this potential method of
05:38 hiding data so you do things like this
05:41 and you research things plus I have my
05:43 own background which I've talked about
05:44 several times with artificial
05:45 intelligence which is extremely light
05:49 okay but we have code that's being
05:51 called AI that's not a I and then you
05:54 have code that's AI that's not
05:56 understood by the public at all and I
06:00 think I think I'm gonna be able to
06:02 describe for you guys sort of the
06:04 genetic difference between the two so
06:06 that when you have a conversation you
06:07 can say well each one of these
06:10 disciplines are really powerful in terms
06:13 of changing the world but they don't
06:16 necessarily all qualify as artificial
06:19 intelligence now what you need to know
06:21 is that when AI first was you know
06:24 theorized to was in the 40s and this
06:28 gentleman by the name of Turing was a
06:30 British computer scientist before
06:33 computers were really well known he's
06:35 also a brilliant mathematician he
06:39 created what's called the Turing test
06:41 which is a test that he barely got to
06:45 see used and in his honor they kept this
06:50 test and they still have it to this day
06:52 which is you have a wall and a computer
06:56 and the other computers on the other
06:59 side and humans on this side talking to
07:03 the AI asking it questions
07:05 answering questions and at the end of
07:09 the test the humans got to predict
07:11 whether or not they're talking to a
07:12 computer or talking to a human on the
07:14 other side so the control test is
07:16 another human on the other side and the
07:18 true Turing test if you can pass is a as
07:21 a program on the other side even the
07:25 first Turing tests in my opinion lacked
07:29 true neural net predictability models
07:34 and learning like especially big machine
07:36 learning algorithms to conduct this test
07:40 now in the more recent decades it has
07:42 truly been artificial intelligence
07:44 that's having this conversation with the
07:46 human but a lot of folks and I even use
07:49 it incorrectly in conversations with
07:52 people who are other engineers because
07:56 it helps them understand generally what
07:59 the code does like I write code from
08:02 time to time where let's say you have a
08:07 bunch of old data and it needs to get
08:09 converted to the new data and it's not
08:12 ever going to be a clean conversion I
08:15 can't just write code to make it all
08:16 happen I've got to have a human in
08:18 between sifting that code from old to
08:20 new and so I will write an interface
08:24 where as the human cleans up the data
08:27 I am memorizing every single thing using
08:31 code such that the next time I have to
08:34 convert that particular chunk of data
08:36 everything the human did is
08:38 automatically done to it and then it
08:39 goes to the side and so I can batch
08:42 process data for testing and then
08:44 eventually release right and then you
08:47 started asking that question the old
08:48 question Oh what is intelligence right
08:51 what makes us real and what makes a
08:53 computer artificial well we'll postpone
08:56 the philosophical answer to that or
08:59 observations on that towards the end of
09:00 the episode you don't a calculator for
09:05 instance has been taught how to do
09:07 mathematical equations so someone could
09:10 say that that's artificial intelligence
09:11 I'm going to say that a calculator is a
09:14 calculator it is computing things that
09:16 is doing you know
09:19 mathematical functions it's a little bit
09:23 different than it starting up the
09:25 calculator the next day if the
09:27 calculator were to go hi Lisa
09:29 are we gonna do some more math today you
09:32 know I'm all ready for your sine cosine
09:34 calculations I've been thinking about it
09:36 and I know how to do them faster you
09:38 know it might see you enter the same
09:41 kind of data four or five times and go
09:43 oh I understand that price that you
09:46 started entering for decimal I know that
09:49 the sense is 25 cents because out of all
09:51 the data you've ever entered into me
09:53 everything that starts with four ends
09:55 with a decimal place of a decimal value
09:57 of 0.25 that might be an artificial
10:01 intelligence calculator that is now
10:03 learning from everything that you do but
10:06 that would just be a small little
10:08 predictability code where the code has a
10:10 little lookup table where it goes okay
10:12 let's keep track of everything and you
10:14 have to understand that the coder who's
10:17 putting together the calculator like
10:18 that if the coder can't conceive of that
10:21 particular value meaning you know it's a
10:26 value to you that the this job is being
10:29 made simple for you it's being
10:31 simplified for you out of predictability
10:32 if they can't conceive of it then it'll
10:35 never do it in a typical normal code
10:40 sort of scenario but now if you get to
10:44 true artificial intelligence now you
10:45 start to metabolize as many dimensions
10:50 of reality as you can possibly give a
10:51 piece of software so software could be
10:56 programmed to learn all any aspect of
10:59 predictability of its use for instance I
11:04 give you like a crude example maybe you
11:08 have a computer in your house that's
11:09 sitting in the front room and it's for
11:13 the whole family and you have one
11:15 account logged in the whole time it's
11:17 just the home account it's not dad it's
11:19 not mom it's not the kids but the
11:21 computer could be taught to say your job
11:26 is to try to figure out who's using the
11:28 computer such that you can start
11:31 crafting
11:32 the availability of applications and
11:34 data and webpages for that particular
11:36 person I get it ready if dad's back you
11:39 might want to check the sports scores
11:40 you might want to do something else do
11:42 some accounting mom might have her whole
11:45 thing kids will have all their
11:46 individual personalities and one of the
11:50 you know if a coders clever let's put it
11:52 this way they could they could simply
11:55 study the movement habits of a mouse the
12:00 speed at which someone types and the
12:02 type of keys that they type in correctly
12:04 you know the the twelve-year-old son
12:07 might be typing the letter R wrong and
12:09 constantly the daughter might do too
12:13 many spaces or something you know just
12:15 just a different behavior mechanism and
12:17 once they can kind of figure out oh
12:18 we've probably switched users like
12:21 seeing this thing move a lot faster
12:22 someone just opened a web browser and
12:24 went for the sports page of the espn.com
12:27 and they could start feeling who's on
12:31 the system and change the behavior
12:34 accordingly the mouse could be
12:36 programmed to really give empirical data
12:38 a little finger touches the first left
12:41 you know button and you read the
12:43 fingerprint and you know exactly who's
12:45 on the computer it has to be up to the
12:48 engineers to give it its intelligence
12:52 another little qualification in my own
12:55 brain is if you can expect it to do
13:02 something it starts becoming more code
13:04 like if it starts to become more chaotic
13:07 and behavior like a human being I didn't
13:10 know what you were gonna say next
13:11 otherwise I could have set it right on
13:12 top of your sentence then it starts to
13:15 having its own personality its own
13:18 intelligence another factor of life as
13:22 human beings is the self-preservation of
13:26 life don't kill me don't hurt me so you
13:32 have to if you were going to extend that
13:34 dimension of recognition to a piece of
13:37 software well what is death what is life
13:39 death might be turning the computer off
13:40 life is give a turning it on you start
13:44 filling up a harddrive filling up memory
13:45 so it's starting
13:46 shut down because they can't do anything
13:48 that might be a sickness or a death
13:50 depending another computers programmed
13:52 to interpret it but the you know the
13:55 huge thing that Kurt's Wells trying to
13:57 do is a mechanical issue what he started
14:03 doing before he got into the computer
14:05 side of things was to study the human
14:07 mind every single biological component
14:12 of the human brain the chemical storage
14:16 and distribution and firing he's studied
14:20 that under duress under happiness under
14:23 all the emotional spectrums to figure
14:26 out how the brain works now probably the
14:31 misnomer is that you have a lot of bad
14:34 science when it comes to the brain but
14:37 tremendous amount of speculation about
14:39 how things work just think about how
14:41 many times we've talked about what
14:43 dreams are how many times they tell you
14:45 that you dream in a split second every
14:47 night you can't possibly dream anything
14:49 you can't dream any further than your
14:51 rim your random eye movement stage and
14:54 everything happens in that little little
14:57 blip of time I dream all night I dream
15:00 all night all morning I mean I can get
15:04 up go the restroom go back to bed go
15:06 right into the same dream literally like
15:09 wait a minute guys something's bother
15:10 oh I gotta pee whoa bareback boom go the
15:12 restroom come back jump in the bed boom
15:14 the dream goes on it's all night long
15:16 well what am i in rim all night
15:18 according to dream specialists okay if
15:22 you don't sink down to that Delta and
15:25 beta phase really like super deep theta
15:28 phase you don't get any really decent
15:30 sleep well I feel fine in the morning
15:34 sometimes I feel disoriented because the
15:36 dream is so realistic that I have to
15:38 literally convince myself this one's
15:41 real now this is room now right one of
15:44 the age-old issues with artificial
15:45 intelligence which they're trying to
15:49 definitely push through and this has
15:51 been something that's been going on for
15:52 probably 40 years which is that when you
15:55 start to look at the anatomy of a human
15:57 body as it feeds the brain
16:00 if you want to mock the brain you're
16:03 going to have to duplicate the input
16:05 systems of a human being what is that
16:08 you've got you know sight and sound and
16:13 touch those are three huge things that
16:15 if Boston Dynamics wanted to put that on
16:19 a robot remember data he was captured by
16:22 the Borg and he had been had his
16:26 emotional circuit disabled he purposely
16:28 did that because when he turned it on
16:30 once when he had to have an episode
16:32 where he went got it and then he put it
16:34 in he turned it on and he just became so
16:37 infantile that it was hard for him to
16:39 manage because his body was probably in
16:42 its 30s at the time and he had zero
16:48 emotional intelligence and so it was too
16:50 much so he turned it off then the Borg
16:52 chick gets ahold of him turns it back on
16:54 so Zahn - his arm a piece of skin
16:58 artificial skin with those hairs they
17:00 look really creepy in the episode right
17:01 and she blew on it and he was like oh my
17:03 god that's amazing she says yeah would
17:05 you like to have this all over you
17:08 not only have your emotional circuit on
17:11 but your whole body's gonna feel what a
17:12 human feels it was very luring for him
17:15 right so let's say you could put a
17:18 camera on a robot put microphones where
17:21 there would be ears and you could
17:24 definitely create a skin of some sort
17:26 that would report back that it's being
17:27 touched you could even put sensitive
17:31 skin touch to hard
17:32 touch light and but you'd have to
17:34 program the parameters of what is hard
17:35 what is light if the if the fabric was
17:40 damaged because it was hit so hard
17:42 you would have to program the paradigm
17:45 inside this ai of pain which means the
17:50 unit is going to try and reflux away
17:52 from it assess the room find out what's
17:55 doing it if the rooms on fire they're
17:57 gonna have to either put the thing out
17:58 or get the hell out one of the - it's a
18:01 difficult difficult thing just with
18:03 those three basic senses now talk about
18:08 taste
18:10 flavor right your flavor is a mixture
18:14 between and smell right your flavor is
18:18 taste and smell mixed together without
18:20 those two interacting you don't get a
18:22 flavor interesting right well they could
18:27 study the palette of a human than
18:29 average human and say okay cheese when
18:34 it's taste this way and smelled this way
18:36 it tastes this way and I mean as this
18:37 flavor and it's it's good or bad
18:41 what would the programmer do would it be
18:45 like the engineer that made data from
18:47 Star Trek he just gave him his own
18:49 preferences so artificial intelligence
18:52 is much much bigger than average
18:56 computational logic gates we talk about
19:01 censorship a lot right and we know that
19:04 there are there BOTS out there little
19:07 programs that run and you know what
19:09 almost everything on your computers are
19:11 bought other than an application but
19:13 even an application once it's launched
19:14 kind of turns into a little instance of
19:16 a bot it's sitting there listening to
19:18 our my own deck on my own deck on my own
19:21 deck meaning is that the most current
19:22 application and if it is it's sensing
19:24 all the inputs from you and going back
19:26 and doing something with data and
19:27 bringing it back and showing you the new
19:29 screen you're in a paint application
19:32 you're just typing the letter will show
19:34 up it's just a little eco system it's
19:37 very similar to the human body a
19:38 computer is very similar to the human
19:40 body the memory is your your
19:44 consciousness the storage is your
19:46 long-term memory the CPU is your brain
19:49 and all the input devices are your body
19:54 parts okay but there was something
19:59 invented I don't know exactly what year
20:02 was invented I think by the 70s it was
20:04 pretty well given its term and being
20:07 used which was a neural net and this
20:11 theory is a theory of it's a tree of
20:15 little nodes as they would call them
20:17 typically drawn oral circles and what is
20:21 up happening is based on what this are
20:23 official intelligence has been taught to
20:25 do those neural nets have a purpose they
20:29 try things and they fail and they're
20:31 trying to find the successful algorithm
20:33 for every outcome that they're being
20:34 tasked to do that was the most basic
20:37 model of it learning language for
20:41 instance one of the projects I've worked
20:43 on as a kid in in high school was to
20:48 create a database that essentially
20:51 learned word associations and a
20:54 predictability model and so what what I
20:57 did was I program this thing that could
20:59 read anything that you gave it and at
21:01 the time it was much more difficult just
21:02 to say here's a book right because we
21:06 didn't have books on tape or you know
21:07 book sons on hard drives or whatever at
21:10 the time and we didn't have the internet
21:12 the way we have it today so today you
21:15 could build this AI to say okay you're
21:17 gonna study every word used in English
21:20 literature whether it's someone's citing
21:22 a Greek word or a French word or
21:24 whatever you're gonna still put it in
21:25 the database and you're gonna read book
21:28 after book after book you're gonna read
21:30 web pages gazillions of paragraphs of
21:34 things and you will develop over time
21:37 this word associations such that just
21:40 like Westworld one word has the
21:42 predictability of another word of
21:44 another word and another word based on
21:46 an objective of some sort what are we
21:49 talking about today we're gonna talk
21:50 about going to the moon
21:52 all right well right there just that
21:54 moon preference the computer if it was
22:00 educated properly we'll look at the word
22:02 moon in everything it's ever read in the
22:04 past especially with going to the moon
22:07 and it starts to harvest up into its
22:10 consciousness well these are the kind of
22:12 words that are used to have this
22:14 conversation and then the AI probably is
22:17 going to either answer questions for you
22:20 which is probably a lot easier or it's
22:22 going to query information out of you it
22:25 wants to ask you a question forming the
22:27 question after a while becomes fairly
22:29 simple what you get back in return well
22:32 it's looking it's parsing a sentence it
22:34 knows a verb now
22:36 an adverb and adjectives all these
22:37 things so it knows what is decorative it
22:41 knows what is core to the concept that's
22:45 being discussed it knows if if taught
22:48 properly okay there's certain words are
22:51 simply used for emphasis how hot is it
22:56 it's very hot oh well who is saying that
22:59 a human being saying that well okay so
23:01 according to a human being very hot
23:04 could be when talking just about the
23:06 human body could be 150 degrees plus 200
23:09 degrees Fahrenheit right but if you're
23:12 having a conversation about melting
23:14 metal or steel to forge something ah
23:16 well now that could look up a periodic
23:18 table and look at it and go well very
23:20 hot and a chemical conversation could
23:23 mean something different this is which
23:25 you can program a neural net to
23:29 understand but you always have to tell
23:31 it what to do none of this stuff
23:35 initially could help itself
23:38 okay so fast-forward to today now what
23:41 they're doing is kind of clever they're
23:45 having artificial intelligence AIS these
23:49 ones that have consciousness sort of
23:52 clean they can go right through a Turing
23:54 test in two seconds no problem at all
23:57 but now they're seeing how much they can
24:00 teach themselves by talking to each
24:03 other and so they can share information
24:05 back and forth between two completely
24:08 different disciplines if they wanted to
24:10 again it's infinite what what could
24:11 actually take place they're now having a
24:14 guys talk to each other to sift out
24:16 further stuff now what you need to
24:19 understand is that a lot of what it
24:21 discovers and a lot of what it concludes
24:23 and these neural nets is trash
24:25 absolutely absolutely useless and
24:29 because the human being gets outclassed
24:32 very quickly with that much data we
24:34 don't hold in our consciousness you know
24:37 terabytes and terabytes of data but
24:39 these a eyes the big ones that are
24:42 behind closed doors or petabytes I mean
24:45 we're talking billions of trillions
24:46 right
24:49 and so it depends on what it's looking
24:52 for now one of the more recent changes
24:55 I'd say in last twenty years easily is
24:58 that the coders have figured out how to
25:01 endow programs with the capability of
25:04 writing their own code so when it starts
25:08 making mistakes
25:10 it can start rewriting and this is sort
25:12 of what a neural net does anyway but it
25:14 can start rewriting its core code module
25:17 by module and so you could take that as
25:22 far as you could conceive of it it
25:24 writes its own module and that module
25:26 ends up having a lot of errors and so it
25:28 either rewrites that R or erases it
25:31 tries to figure out maybe diagnose
25:34 what's going wrong with this module so
25:37 it get really messy really quickly but
25:42 anytime you've ever seen an artificial
25:43 intelligence do anything that impresses
25:45 you you have to understand that that is
25:47 a demonstration up to this point in time
25:51 of a particular outcome that was
25:55 synthesized by mankind so if you had an
25:59 AI like the one in wargames which I'm
26:02 sure by the time wargames was made it
26:04 was that eighty two or three somewhere
26:06 in there Matthew Broderick might have
26:09 been before that but anyway that movie
26:12 was written about a friend of mine
26:14 honestly the military had definitely
26:18 taken computers to that level to run a
26:20 billion trillion simulations of some
26:23 global thermonuclear war and found out
26:25 that you know no one can ever win ever
26:27 you know they just keep re scrambling
26:31 the data and the Russians did the same
26:32 thing I'm certain of it which is where
26:35 you get to the point where grown-ups
26:37 don't have nuclear wars they don't which
26:40 is why we never had one and probably
26:42 never will the only way we're ever going
26:44 to have a nuclear war is if some rogue
26:46 agency or in a billion to a billion to
26:50 one chance one person gains the
26:53 capability of doing it all by themselves
26:57 it's not inconceivable but they also
27:01 don't build things without fail-safes
27:03 and so if some missile launches there's
27:05 other redundant systems that can blow
27:07 that thing out of the sky before it ever
27:08 goes critical so you might have a
27:10 nuclear warhead coming but if its
27:12 propulsion system explodes or a star
27:15 wars system zaps it out of the sky it
27:19 will never detonate as a nuclear bomb
27:21 they have moments when they're armed in
27:23 moments when they aren't right I don't
27:27 think it'll ever happen personally but
27:30 you have in the last two years before
27:33 Stephen W Hawking died he came out I
27:37 think on a Monday and he said oh my gosh
27:40 I have been shown artificial
27:41 intelligence that terrifies me never
27:45 said what it was right I mean that's the
27:48 thing that's like really if I told you I
27:51 went to the supermarket and I found some
27:52 produce that looked lethal I wouldn't
27:56 just walk out of the out of that grocery
27:59 store and get my cell phone and start
28:01 transmitting on social media oh my god
28:03 there's a Trader Joe's where I live and
28:04 they're selling lethal apples I you know
28:07 you get rid of the apples quite when you
28:09 see them you don't leave the place until
28:11 they're addressed right and you don't
28:14 run your mouth if you thought you were
28:16 being followed by men and black that
28:17 we're gonna you know grab you because
28:19 you saw these apples you wouldn't say
28:20 anything at all if you thought you're
28:21 gonna die you know if you had the one
28:24 transmission to the whole world maybe
28:26 you do that but none of us do so you can
28:28 keep your mouth shut
28:30 so for Hawking to say that immediately
28:33 perk my ears because I'm like [ __ ]
28:35 that's that's all I could say okay by
28:38 Thursday or Friday the same week you
28:40 have Elon Musk quoting the exact phrase
28:44 he was shown artificial intelligence and
28:47 it terrified him okay dude and he's
28:50 doing it in an interview at his SpaceX
28:52 joint so sitting at a desk not telling
28:55 anybody what it is
28:57 well artificial intelligence being
28:59 attached to terrifying you don't need
29:03 any AI really you need that other stuff
29:06 I'm talking about the the logic gate
29:08 code stuff that's not necessarily AI a
29:11 little bit of learning but if anything
29:13 learns and you consider that a an
29:15 artificial intelligence than bike
29:16 like everything almost every piece of
29:18 code is artificial intelligence the
29:20 second that it finds your preference
29:22 right now what I focused on on my first
29:25 step is so which I just want to briefly
29:26 recap for you guys is if you want to be
29:29 afraid okay you can be afraid of code
29:33 all day long and maybe you know there's
29:36 probably some point in your brain where
29:38 you should remember what I'm about to
29:39 say I just think that we have other
29:42 forces that keeps this kind of stuff in
29:44 check if you thought the leaders of the
29:47 world we're going to somehow build you
29:50 know in some short period of time with
29:52 no one knowing you know millions and
29:54 millions of robots like the one a black
29:56 mirror and they were just going to leash
29:58 him on the world you know some factory
30:00 that works at night you know with robots
30:01 there's no humans present the whole
30:03 record of this being done is being
30:05 hidden okay well you could go to that
30:08 total extreme and freak out you know
30:12 they've got these robots I just watched
30:14 a special on YouTube about military
30:15 robots that are Declassified you can go
30:18 see them and they're they're still kind
30:21 of clunky as [ __ ] you know but they're
30:22 you know I got little tiny ones that can
30:24 crawl upstairs and stuff they just look
30:25 like little ones you'd find on Robot
30:27 Wars you know but as long as you had a
30:30 robot okay
30:32 driving down a neighborhood street we
30:35 have technology probably 25 30 years ago
30:39 aboveboard off-the-shelf technology
30:41 where you could have optics you know
30:43 maybe two cameras three cameras four
30:46 cameras some 360 set up and you could do
30:48 it 30 years ago you just gotta have the
30:50 money to do it if it has thermal cameras
30:54 they can sense what's alive what's not
30:55 alive and then you can use lasers or
30:59 sound to figure out how far away an
31:01 object is it just basically sends it out
31:03 bounces back and they measure the trip
31:06 and that tells on how far away it is and
31:08 then based on that the image size at
31:11 that distance will tell the computer
31:13 inside with very little code that's how
31:15 big that thing is that heat signature is
31:18 a cat that heat signature is a human
31:20 shoot human right you put enough bullets
31:24 in this thing and some guns you can put
31:26 one you could put four you could put ten
31:27 it just depends on how they want to
31:29 build this thing
31:30 and he could just mow down everybody in
31:32 the neighborhood just drive right down
31:33 the street you give it a big enough gun
31:35 it could go through walls right now the
31:38 huge challenge with these robots which
31:41 we can only assume that they've solved
31:43 these issues behind closed doors in the
31:46 military level it's the power supply
31:48 that's the huge huge thing we are told
31:53 by the Patent Office all around the
31:54 world patent offices around the world
31:56 that they will not allow you to register
31:58 a perpetual motor any type of power
32:01 supply that is infinite they say that's
32:03 impossible because of all these laws of
32:05 physics that they wrote down back in
32:07 Einstein's deceptive days right and
32:10 they'll quote Newton and all this stuff
32:11 but I think we know there's some options
32:15 out there but I don't know if it's at
32:17 the level of running a gigantic robot
32:18 that's got lots of motors and you know
32:22 has to run the CPU it's got to run so
32:24 fast that it can take in all this data
32:25 and make it real time the faster a
32:28 processor metabolizes electrons it's
32:32 like when you rub your hands together
32:34 really really fast and you get friction
32:35 well the more you put electrons through
32:39 silicon it's a friction situation which
32:42 is why your computer gets so hot on your
32:44 laptop on your lap when you're playing a
32:47 video game or something or while the fan
32:48 goes on if you're processing video it is
32:51 cramming electrons through that
32:52 processor as quickly as possible so
32:55 you'd have to cool the system as well
32:57 most you gamers know that the most
32:59 efficient way to cool a computer is
33:01 through a water cooling system now the
33:04 smaller and smaller they make a chip the
33:07 more they can get stuff done with less
33:09 power and thus it gets faster and faster
33:12 with less power so that's it's a nice
33:15 thing but typically currently you know
33:17 laptops cost twice as much desktops and
33:20 they're half the speed I mean it's just
33:21 an IQ test
33:22 everybody's failing but I gotta be
33:24 mobile oh really really you're gonna go
33:26 to a coffee shop every single day if
33:28 you're in college I get it but if you're
33:30 an adult really well where are some of
33:34 the areas that were concerned about
33:35 artificial intelligence well any of you
33:39 who saw Minority Report and and followed
33:41 it afterwards you realize that they have
33:44 mastered okay social media is the number
33:48 one platform for this they have mastered
33:51 watching your habits online and then
33:55 sharing the data and then using big
33:57 machine algorithms to figure out your
33:58 profile what kind of person are you they
34:02 look at your credit cards they look at
34:04 every single interaction you have with
34:05 the world as long as you're on the grids
34:07 if you buy things with credit cards ATM
34:08 cards they know exactly what you got
34:12 when you got in how much you got
34:13 and so that assists them in their
34:16 profiling of who you are they can look
34:19 at the GPS coordinates on your phone
34:21 figure out where you drive if an
34:22 establish he's at this business she's at
34:24 this coffee shop that did it uh if you
34:28 don't leave your house they'll know that
34:29 - personal phone calls on landlines they
34:33 know that - everything everything you do
34:36 because they listen to everything that
34:37 you say that's another data set that
34:40 goes in there that says this person
34:42 believes in conspiracy theories this
34:43 person believes everything that we tell
34:45 them this person is this much right wing
34:49 this person's that much left wing they
34:50 know this person is a vigilante you know
34:54 and they knew all these they know all
34:55 this stuff and so based on what you
35:00 think they could do with that
35:02 information is how scary that is to you
35:06 now we all know that the number one goal
35:09 of any controlling body in the world is
35:11 control they want to maintain control
35:14 see what they can get away with power
35:17 corrupts absolute number that and as
35:22 soon as you gain control you gain power
35:24 and as soon as you gain power you get to
35:28 have everything you want and you can
35:30 take it from anyone that has it if
35:33 that's your goal again it's really
35:35 really tough when well it's let's
35:39 digress for one second on purpose here
35:41 there's something about the hubris of
35:44 man which is very natural and I think
35:46 that almost every single one of us
35:48 suffers from some microscopic level of
35:51 this even if you're an extremely good
35:52 hearted person you couldn't take a
35:54 minister
35:55 from some church that you couldn't say
35:56 anything bad about if they if a human
36:00 being experiences massive fortune in
36:02 their life even if they've had a
36:05 hardship and then they got into this
36:07 beautiful moment in their life it's hard
36:11 for them not to wake up in the morning
36:13 and say I must be special because
36:16 special things happen to me you know I
36:19 always have a job makes a lot of money
36:21 or if I fall down I can get back up and
36:23 get you know get rolling again I've got
36:25 a beautiful husband beautiful wife
36:26 beautiful kids beautiful family I live
36:28 in a great town I always drive a fancy
36:30 car live in a nice house I can go
36:32 anywhere I want whenever I want eat
36:33 whatever food I want I've got
36:36 powerful friends famous friends whatever
36:39 you think makes you a success the more
36:42 that you gain that it's hard not to say
36:45 to yourself even if you don't admit it
36:48 to the public must be something good
36:50 about me and that is the glint pin that
36:54 feeds this narcissism that is the
36:57 ultimate corruption of power in my
37:00 opinion so the other thing that is the
37:08 dilemma of man that fuels artificial
37:10 intelligence divisions around the world
37:13 is that man can conceive of perfection
37:18 he really can he's in a number system
37:22 pretty perfect it just starts at zero
37:24 and goes up to infinity if you want to
37:26 count backwards you can do that too into
37:28 the negatives you can go into
37:31 subdivisions decimal places right ask
37:33 anyone who owns bitcoins how much you
37:35 can split a coin we can conceive of
37:37 perfection we can see we can close our
37:39 eyes like Aristotle said and see a
37:43 perfect circle but then when we open our
37:46 eyes grab a pen and try to draw one we
37:48 can't do it which is why we use
37:50 computers and machinery to create
37:52 perfect circles mm-hmm anyone who deals
37:56 with super complex mathematics they
38:00 don't want to do long division by
38:01 themselves they don't want to do sine
38:02 cosine calculate PI out to a hundred
38:05 decimal places they don't want to do
38:06 that but they want that accuracy and
38:08 they want that
38:09 math to be completed and so they create
38:10 a machine called a computer slash
38:12 calculator to do that work for them the
38:18 reason I mentioned these little examples
38:19 which I know is kind of insulting to
38:21 your intelligence is that man because of
38:27 our by proxy of those thoughts can
38:29 conceive of a perfect man meaning
38:34 mankind ladies and so this whole thing
38:39 with you know androids or replicants or
38:42 robots or something like that where they
38:44 we could have a partner in our house to
38:48 help out with the chores to help raise
38:50 the kids to mow the lawn whatever you
38:53 needed to do it's sort of this fairly
38:57 immediate goal of mankind to be able to
39:00 do that you know Sony's been hurt not
39:02 was an acai Toyota has been creating
39:03 those little robots you can see a
39:05 disneyland Boston Dynamics is creating
39:08 it all in the name of the military but
39:10 robotics is probably one of the biggest
39:12 industries in the world right now but
39:15 it's a multi-discipline thing isn't it
39:16 you have whole teams trying to build the
39:19 the the actual physical structure to
39:24 accomplish a physical apart if I should
39:26 say a particular goal so when you want
39:28 it to be humanoid you're going to go for
39:30 a human set of things that other devices
39:33 can't do when you want it to be more
39:36 tank like it's gonna have tracks on it
39:38 and it's going to be more military
39:39 combat based right we now have well
39:44 we've had jets now for 35 years it could
39:46 fly themselves we just choose to put the
39:48 human inside because the artificial
39:50 intelligence wasn't up to snuff and we
39:53 didn't have the communications backbone
39:55 that we have now to talk to that device
39:57 in a way that someone could pilot it
40:00 from afar which is what we have with
40:01 drones now remember drones have very
40:06 little AI in them simply because we
40:09 don't trust them now there probably are
40:11 some out there that again that are
40:13 covert and it's very difficult for me to
40:15 talk about what's happened behind closed
40:16 doors I don't really have any any
40:19 contacts in that realm whatsoever so
40:22 I have people that were in that realm
40:25 that had been out of that realm for a
40:26 really long time and you know the and
40:33 when you watch how languages mature
40:35 because programming languages have to
40:37 mature to the ability to be able to
40:39 write code that is able to write itself
40:42 to handle neural nets properly you have
40:45 to have processors and and systems that
40:49 can actually handle what the task is and
40:52 a lot of thats kept covert for and it's
40:55 probably a lot less than what we think
40:56 now it used to be that the military we
40:58 would always say is 20 years ahead of
40:59 the rest yeah I think that the only way
41:05 that could be true would be in very
41:07 specialized areas like perhaps aircraft
41:10 military equipment of certain sort or
41:13 certain types but in terms of a bunch of
41:18 super fast CPUs super fast pieces of
41:22 hardware that we don't have access to
41:23 I'm sure those exists okay but you know
41:28 Intel is not sitting there up in the bay
41:31 area of San Francisco area San Jose area
41:34 not trying to make chips as small as
41:36 they possibly can there they're
41:38 literally scientists up there the second
41:41 they're able to do it they'll they'll
41:42 tell you you know it's a big deal it's
41:45 like a pharmaceutical company creating a
41:46 drug that starts to cure cancer and even
41:49 if they haven't finished clinical trials
41:51 they'll start pumping the PR to say
41:53 we're gonna have this hopefully and you
41:54 know trust us but what are the needs of
41:59 an average man because that really gets
42:01 at the the huge thrust of what would you
42:06 create a a I to do well you and I have
42:10 our list of things a robot like I just
42:13 said they helped her out around the
42:15 house the whole George Jetson lifestyle
42:17 we'd like to live
42:18 Blade Runner advanced a different
42:23 narrative which was interesting which is
42:26 humanoid robots made by the Tyrell
42:29 corporation that it would go offworld
42:34 in hostile conditions do be able to do
42:41 things that were hazardous to humans and
42:43 maybe in being a radioactive very hot
42:46 area or an area just where you could die
42:49 because something's gonna happen so the
42:51 robot has been built tougher smarter
42:53 faster stronger all that good stuff so
42:57 someone in industry might be like geez
42:59 if I could have someone you know pick
43:03 crops or get rid of weeds then I
43:05 wouldn't have to use a chemical called
43:07 roundup glyphosate to get rid of all
43:09 this stuff and that could be the case in
43:11 the movie run away with gene Simmons and
43:16 Tom Selleck that's exactly what they had
43:18 in that movie was these little robots
43:19 that would do all your your vegetation
43:22 for you I prefer that over any poison
43:25 wouldn't you there was a Twilight Zone I
43:28 think was called sing the body electric
43:30 and it was about a gentleman who had
43:35 three kids and the mother had passed
43:38 away his wife had passed away and his
43:40 mother-in-law I think it was his mother
43:44 or his mother was just riding his ass
43:46 about how he worked too much and how he
43:48 never spent in time with his kids and
43:50 the nannies kept quitting for one reason
43:53 or another they liked the kids or
43:55 something like that and so he went down
43:56 to this local shop and bought an Android
44:00 nanny who was essentially I think this
44:04 was even before Mary Poppins came out
44:06 not that the story wasn't much older but
44:08 it was a Mary Poppins kind of lady shows
44:09 up and really engages the kids but one
44:13 one of the daughters in the story
44:15 wouldn't accept her even though she
44:17 looked perfectly human until there was a
44:20 near-death experience and she eventually
44:22 apologized they lived happily ever after
44:24 then all the kids grow up the chick
44:27 finally leaves because they're all in
44:28 their 20s and she goes off and helps
44:32 another family so that's one of the
44:35 visions that we have for how complex and
44:38 artificial intelligence could be but now
44:40 imagine that you're just building a
44:43 nanny with this neural net well all of
44:46 your objectives from that point forward
44:48 is to
44:48 raise children to really be concerned
44:50 about the safety of children as it
44:52 applies to their physical safety their
44:55 nutritional safety their sleep habits
44:58 everything their educational safety
45:00 right making sure they do their homework
45:01 and learn things and just generally do
45:04 happy fun things as well
45:06 crafts arts go out and play at the
45:08 playground whatever so you could hone
45:11 that down and really potentially today
45:14 okay at least have the program fairly
45:18 intelligent even though everything else
45:20 is simulated what we're concerned about
45:23 and this is where the hulking musk
45:28 caution sort of angers me is one when
45:32 they say that kind of stuff and then
45:33 don't cough up the what they saw
45:36 sounds like [ __ ] and it sounds like
45:39 they're literally engaging in
45:41 fear-mongering to the people and what's
45:45 crazy about it is when NASA sells all
45:47 their fear you know doom and gloom oh
45:50 just came out yesterday a city killer
45:53 asteroid came really close to Earth
45:56 right never happened in our lifetime
45:57 right at least you can say oh I better
46:01 pay my taxes so that NASA can have their
46:03 60 million dollars a day so if they can
46:05 try to knock this stuff out of the sky
46:07 even though every time you ask NASA
46:09 could you really knock that at the Scott
46:10 and they go hell no even if we knew it
46:12 was coming what are we gonna do nuke it
46:14 nothing we can do we don't have enough
46:16 time we never have enough time oh
46:18 they've got a lot of theories about how
46:20 to land craft on a meet on a meteorite
46:23 of some sort and then start focusing
46:26 light on it to create a big lens effect
46:28 to start burning one side of it to
46:29 create like a motor to move it out of
46:31 the way yeah right yeah a rock the size
46:35 of New York's gonna respond to what
46:37 level of force and the vacuum of space
46:39 none if anything like that was supposed
46:42 to happen because God put it there it's
46:46 gonna happen and we're just gonna have
46:48 to weather through it right but when
46:50 someone new instills fear in you with
46:53 this unknown ok first they're socially
46:56 being here responsible not to Lisa
46:58 the category that we should be concerned
47:01 about but now let's just break it down
47:04 let's just break it down they're telling
47:07 you that they saw something that made
47:08 them afraid all right what could that be
47:11 let's just parse that because I think
47:13 that's not that hard to to discuss well
47:17 one it could be some human exterminating
47:21 robot that's being designed just like
47:23 black mirror everything else in black
47:25 bears come true right so this little
47:27 robot looks like a little dog which is
47:29 also in the script that was stolen it
47:33 has a bunch of stuff in it right has
47:34 little guns as little tiny darts that
47:36 our GPS darts that stick into your flesh
47:39 they just blast you and then these
47:41 little things stick inside your skin and
47:42 as a GPS coordinate and you're trying to
47:44 get them out of your skin you know and
47:46 it's chasing you the whole time it's got
47:47 just a little gun barrel enough bullets
47:50 in it that it can shoot you if one of
47:53 them breaks down because you hit it with
47:54 a baseball bat or run over it with the
47:56 semi-truck well if there's anything
47:58 salvageable from that robot in in black
48:00 mirror the little guy is this little
48:02 friends of the same species would come
48:04 and pick it apart and and then put put
48:06 together with other parts and rebuild it
48:09 so the AI see distinctly two different
48:14 categories that threaten mankind and
48:18 then there's kind of a fringy third one
48:20 which will probably come first to be
48:21 honest the fringy third one is
48:23 essentially replacing you at your job
48:27 something you're doing can be taught to
48:29 a computer and it just learns how to do
48:32 it even accounting I mean like seriously
48:34 Mac in tax sorry TurboTax does your
48:38 taxes for you just fill out the
48:39 interview questions and boom well as
48:41 soon as we complete the ecosystem of you
48:43 put all your financial transactions in
48:46 your bank and it knows all the w2
48:49 information is like your 1099
48:51 information any other rewards that
48:54 you've received from retirement vehicles
48:56 or whatever investments well it just
48:57 should be able to tell you at the end of
48:59 the year I just took this out of your
49:00 account this is how much you paid the
49:02 government you don't need an accounting
49:03 firm anymore ever ever ever ever
49:07 theoretically that's possible right so
49:09 the most nefarious one that is
49:12 very direct is that sort of doomsday
49:15 model where some crazy trillionaire in
49:20 the world some banker family or
49:22 something is going to finance in secret
49:24 this army of little BOTS they're gonna
49:26 be released on the world man maybe their
49:28 little flies to go around just inject
49:31 everybody with bad stuff you know I mean
49:33 why they wouldn't just spray it in the
49:34 air I don't know put it into water but
49:37 if it won't exterminate the world or put
49:40 it under lock and key and say look
49:41 you're gonna have those cops like the
49:44 ones in thx 1-1 3-8 movie which if you
49:46 haven't seen is just a bunch of all the
49:48 police are robots all of them and
49:51 they're dressed in like California bike
49:54 cop outfits from the 70s but their faces
49:56 are these chrome mannequin faces they're
49:59 the white helmet on just like a bike cop
50:01 and they have cattle prods and it's only
50:04 you should do what you're supposed to
50:05 they do they leave you alone as long as
50:09 you if you're do anything they don't
50:10 like the cattle prod you and you know
50:12 it's non-lethal but it's not fun to live
50:15 in that world so either it's gonna be
50:17 some it could be I should say some
50:20 extermination event which again doing it
50:22 with robots would be the stupidest way
50:24 to do it wouldn't it wouldn't be
50:26 artificial intelligence if you want to
50:27 kill the whole planet I mean how many
50:30 ways have we created to do this isn't it
50:32 pretty damn infinite
50:34 I mean poisons and binary weapons where
50:37 they feed you a and you eat it all day
50:40 long and it doesn't do anything to you
50:41 and they feed you B and you melt that's
50:44 already that's been around for god I
50:46 don't even know how many decades four or
50:49 five six decades at least they can
50:52 poison water supplies they can poison
50:55 your food we have chemtrails in the sky
50:58 so they could just change the ingredient
51:00 up there and wipe everybody out they
51:03 have cell phone towers everywhere and
51:05 five g's about to be deployed everywhere
51:07 they have HAARP antennas so there's a
51:08 much more economic economical ways to do
51:11 this world extermination if that's what
51:13 they wanted to do
51:14 why have AI do it so that's why I don't
51:17 fear the age of the robots at least in
51:21 my lifetime and maybe if I make it to a
51:24 hundred I might see something that
51:25 freaks
51:26 you know I'll let you guys know the
51:29 other event would be more subtle and
51:32 intent with more intention which would
51:35 be to dial that back from some world
51:37 extermination event to sort of your
51:43 chappie sort of robot your district nine
51:46 sort of species of robots where they
51:49 which is what Boston diamond dynamics
51:51 looks like it's gearing towards and you
51:53 know maybe they need two more decades to
51:55 really pull this off again power
51:56 supplies would have to be utterly
51:59 revolutionized as long as there's some
52:02 nerd on your block that can do an EMP
52:04 weapon and could hide the fact that
52:09 they're doing it then you might be okay
52:11 some starts walking down the street and
52:12 you just zap it it all fries all the
52:15 mechanics inside these things are gonna
52:17 be very susceptible to EMP waves
52:19 probably for a very very long time
52:21 unless there's something they're not
52:22 telling us about technology but let's
52:24 say that we stop fighting wars with
52:26 human beings at least the bigger armies
52:31 aren't using human beings the bigger
52:34 army start using disposable robots hmm
52:39 well there's an economic problem with
52:42 that I guess in the short term because
52:45 the human being in the eyes of a banker
52:48 who refers to us as cattle when we go
52:51 off to war we're there for the slaughter
52:54 or pennies on the dollar in the average
52:57 infantry of any division of military
52:59 anywhere in the world they consider us
53:01 to be cheap labor for the war as soon as
53:06 you start advancing up to you're more
53:07 your Special Ops guys your Rangers your
53:10 seals your Special Forces people etc etc
53:14 then you're dealing with much more
53:16 expensive assets who have endured you
53:19 know millions of dollars worth of
53:21 training I think it was said that the
53:23 average Navy SEAL by the time they
53:25 graduate the amount of money they think
53:27 they've spent on that seal because
53:29 there's so much attrition right so fifty
53:31 guys go in three or four make it through
53:33 that you know the basic first you know
53:37 audition into the class
53:39 I spent over 7 million dollars per
53:41 person at that super duper level so in
53:45 order to make an infantry out of robots
53:48 you got a lot of technical problems to
53:52 deal with way before this century's over
53:55 ok which would be these things would
53:59 have to cost a couple thousand bucks
54:01 from from the beginning maybe ten grand
54:04 you know now we're probably I don't know
54:07 how much did they consider an infantry
54:09 soldier to be worth once they graduate
54:11 maybe a couple hundred thousand dollars
54:12 or something with all the training and
54:13 flying them around and feeding them and
54:15 all that stuff I don't know
54:18 but think about trying to fight a war in
54:23 the desert with robots there's so much
54:26 going on a desert sand is a horrible
54:29 surface to fight on okay we're gonna
54:32 fight up in the hills you're gonna fight
54:34 in an a barren desert you're gonna fight
54:38 in cities cities are super duper complex
54:42 human beings you know know their
54:45 neighborhoods pretty well but you could
54:47 upload to a computer all of the geometry
54:49 of a city all the specifications of a
54:52 building ever they would know every
54:54 single entrance exit and all that kind
54:56 of stuff so you know its potential but
54:59 we're currently I think miles away from
55:03 that right now and then again the
55:07 artificial intelligence unlike the nanny
55:10 who's taking care of your kids is
55:12 programmed for all kid things the
55:14 soldier robots would be only programmed
55:16 for combat they have parameters for what
55:19 is to kill what isn't a kill and what if
55:23 you said okay well they're probably
55:24 going to make it such that maybe they
55:26 find out if a person is armed and if
55:28 they're not armed
55:28 they leave them alone so maybe we cut
55:31 down a lot of collateral damage and then
55:34 what if the artificial intelligence is
55:37 taught to learn who an enemy is and it
55:40 assess the target said it was non-lethal
55:42 and then someone pulled a grenade out of
55:44 their ass or whatever and threw it and
55:46 now all of a sudden if it was a woman
55:49 all the women are now in that
55:52 particular button if it's distributing
55:54 the information to all the other robots
55:55 well jeez now all women are targets
55:57 because one woman decided to attack a
55:59 robot then it goes down to children if
56:04 you're a local and you realize there's
56:05 an adult your target and we still need
56:07 to wire up all these robots we'll get
56:09 all the kids to put a little duct tape
56:10 bombs sticky bombs on everything for a
56:13 little while and then boom boom boom and
56:14 then all the robots want to kill kids
56:16 too so that little algorithm of saving
56:20 humanity with robot wars and hey I don't
56:24 think he quite pans out now back in the
56:28 late 90s someone created an interesting
56:31 video it was a mock situation I
56:34 mentioned it once or twice some of you
56:36 may have actually seen this and it was a
56:40 guy trying to order a pizza and the it
56:44 was brilliantly done someone created it
56:46 a fake piece of software where they were
56:49 ordering a pizza through their computer
56:51 software and they then had the operator
56:54 on the other side who was filtering the
56:58 order and what was happening in this
57:00 scenario was that their medical records
57:02 and all of their life's history was
57:04 being furnished to the pizza place and
57:07 they were saying oh I see that you're
57:10 diabetic well then you can't order the
57:13 coke I see that you're really overweight
57:15 so you can't order the large pizza you
57:18 have this that and the other thing so
57:19 you can't order these ingredients and it
57:21 got down to the point where the person
57:22 really couldn't order anything because
57:24 their data was being shared and it was a
57:28 massively socialistic future where the
57:34 software was not doing anything AI he
57:38 was just comparing data it was just
57:39 saying this I have a database on this
57:41 person in order to get this ingredient
57:43 you have to have good standings with
57:44 your health with society the country
57:47 whatever you can be you know can't be
57:49 some some rebel rouser
57:52 you can't otherwise you lose all your
57:54 privileges which is what the Social
57:56 Credit system is going to do it's
57:59 already doing it okay
58:03 so now let's jump into the philosophical
58:05 side of the conversation because I
58:07 mentioned this and I think one of the
58:11 episodes that I released during the
58:13 summer time but it's very very relevant
58:17 at this exact moment in time and that is
58:21 this idea that because humans are so
58:24 flawed especially when power is
58:27 introduced hence control that it could
58:32 be probably agreed on in any level of
58:36 society that we're gonna have a messy
58:41 world for quite some time because of
58:44 this inability to discipline ourselves
58:46 or I know you know we're unable to
58:48 control all of our emotions all the time
58:50 aren't we so you will have these
58:55 theories discussed there in lots of
58:57 science fiction books and movies where
59:01 humans essentially surrender the overall
59:05 controlling apparatus of their region
59:08 their society their world to AI
59:11 computers and they give it all the
59:15 parameters of a perfect world could even
59:18 be like Logan's Run you have an age
59:20 limit that's enforced you hit 30 and you
59:22 must renew which means die well someone
59:27 could say well that's the only way we're
59:29 ever gonna get a hold of ourselves
59:30 because we're impatient with the human
59:32 condition developing organically over
59:34 time then this kind of thing should be
59:39 done there should be some world computer
59:41 that distributes money distribute
59:42 distributes resources an opportunity and
59:45 determines whether or not you can spawn
59:47 and whether or not you get medical
59:48 treatment and all this other stuff now
59:51 what you need to understand is those in
59:52 control at the time this is created will
59:54 most likely in bed almost a transparent
59:58 recognition system where they don't even
60:00 exist they can go anywhere they want
60:02 nothing will touch them they always have
60:03 infinite resources infinite money
60:05 infinite control it'll be that way how
60:08 they handle their siblings who knows so
60:11 you could have someone pitching the
60:14 Robin Hood theory to you saying look
60:17 we're gonna you know steal from the rich
60:18 give to the poor and a computer is gonna
60:20 control everything
60:22 mm-hmm you know it was in the movie 2001
60:27 a Space Odyssey with the Hal 9000 that
60:30 was giving ultimate givin ultimate
60:31 control over the Odyssey that was flying
60:33 out to Jupiter to see the next iteration
60:36 of the monolith it ended up killing one
60:39 of the members and trying to kill a last
60:41 guy but the AI by time you see the
60:44 second movie in 1984 2010 it was the
60:49 White House that told how what to do
60:52 to kill everybody in hibernation and to
60:54 go after the other two guys I forgot the
60:57 reason why that was the case but that
60:59 was the case and a new Hound was
61:01 actually introduced in 2010 and they had
61:04 put this red calculator that was if you
61:07 type in a certain calculation it was
61:09 going to supposedly fry the brain of the
61:11 computer which I think ended up failing
61:13 at some point if any of you remember the
61:17 original alien they had the computer
61:19 mother and they would go talk to mother
61:26 and figure out what they were allowed to
61:28 do what they could do and then they
61:30 realized one of their Bishop right I
61:34 think I can't write that was the first
61:36 guy's name or not but you know one of
61:38 the guys was an Android on the ship they
61:41 didn't know and by the time aliens came
61:44 around the Android had to admit you know
61:48 that's what he was there were a little
61:50 knife test they figured out he was doing
61:52 the knife test between the fingers
61:53 really really fast
61:55 and he even slipped and cut himself
61:58 which was interesting we are now heading
62:02 towards these what they call hot hotels
62:08 hotels of tomorrow people are trying to
62:11 integrate this stuff in their house as
62:13 much as possible every light switch
62:14 every power outlet everything is hooked
62:16 to some AI such that when you're on
62:19 vacation you can have your house look
62:20 like everybody's living in there and you
62:22 can have appliances turned on and your
62:25 coffee's ready in the morning
62:27 black mirrors touch this with the
62:30 the buds that you put in your head and
62:32 it learns who you are and then you pull
62:34 it out and it's trained to take care of
62:36 you incredible episode transhumanism
62:40 what's that all about well transhumanism
62:42 is you know the sales pitch is something
62:45 like aren't you tired of being flawed
62:47 aren't you proud aren't you tired of
62:49 losing your memory bad eyesight
62:52 you can't run like you used to when you
62:55 were young well we'll just put Bionic
62:58 legs in you and new eyeballs and little
63:01 little subprocessors in your brain and
63:04 it will take care of everything if you
63:05 can't remember something little find out
63:06 what you were trying to remember and
63:08 it'll fetch it for you earlier you get
63:10 this in your body the better because
63:12 then it remembers more the slow boil
63:16 started you know around certain events
63:20 where they wanted to chip everybody
63:22 that's their ultimate first step is to
63:25 put a chip in everyone's body now Europe
63:27 has done various stints with this and
63:30 what everyone finds out is that you get
63:32 cancer right where the chip is because
63:35 any electromagnetic field destroys human
63:38 tissue faster than the immune system can
63:40 fix it yet horrible infections and you
63:42 have to get these things removed out of
63:44 your body any experiments that you hear
63:46 otherwise is usually a lie the chip
63:49 didn't do anything it's just this alien
63:51 thing in your body or they had to take
63:56 it out you didn't tell you but now
64:00 there's a whole side of AI that will be
64:04 very interesting to see who has made
64:06 progress and this in this particular
64:08 area and that is the metaphysical nature
64:10 of humanity now for those of us that
64:14 believe we have a soul and that this is
64:16 a much bigger ecosystem than just being
64:18 human
64:18 there's reincarnation due to an infinite
64:21 life it's pure physics it's not a
64:24 religious thing there is a religious
64:26 element to it but it's probably not as
64:31 accurate as the physics version of it
64:33 which is to say you can't hide energy in
64:34 the universe therefore you reincarnate
64:35 just in an episode about this I know but
64:39 how do you teach an AI
64:41 to cry to love to have loss well for any
64:48 of you that watched watched West world's
64:50 off HBO you know that they have shown
64:54 you a scenario where this happens in a
64:57 fictional sense those hosts had all the
65:02 emotions that anyone has in life period
65:06 loops that they went on alright again
65:13 what would happen with a first
65:17 generation robot /ai that's running the
65:20 robot to create such a thing would be
65:22 that it would eventually probably reveal
65:25 its patterns fairly quickly you would
65:27 find out what would make your robot
65:28 crying what would make your robot happy
65:30 because there's certain triggers in the
65:32 software that would make that happen
65:33 maybe it would take a lot but you know
65:38 there's already little robot dogs and
65:40 cats and and things trying to simulate
65:43 your friends they're trying to put a lot
65:45 of AI into like sex dolls so that people
65:48 stop procreating the depopulation
65:50 algorithm the danger behind that is the
65:54 second that well I'll tell you this is
65:58 something I think I've mentioned briefly
65:59 but it's I heard it the other day in
66:02 some fictional thing and I was so
66:04 thrilled to have somebody else say it it
66:07 just made my day let's say you're single
66:11 and you're lonely and instead of dealing
66:14 with that loneliness by going out and
66:16 meeting another human being and trying
66:18 to figure out how to do that which I
66:20 know depending on what kind of person
66:22 you are could be daunting there's always
66:24 someone out there for you don't give up
66:27 they will get substitutes for human
66:30 beings and this is a much more dangerous
66:34 algorithm than I think humanity realizes
66:37 but those who want us to depopulate love
66:40 this love love love this how many single
66:44 people do you know have an animal and
66:47 they're always single always and you go
66:52 over there and you talk to him about
66:53 their animal and this is nothing against
66:54 animals man
66:55 of pets I'm allergic to most them but I
66:57 love them okay but they end up only
67:02 being able to talk puppy talk Kitty talk
67:06 they don't talk like normal human beings
67:09 and so when they get up with you meet
67:12 normal human beings a lot of times they
67:15 seem normal but sometimes sometimes they
67:17 seem nuts like the cat ladies but they
67:21 start to replace all the human
67:23 development that they need to really
67:25 truly not be alone not to have their
67:27 companion die every eight to 15 years
67:29 depending on what kind of animal they
67:30 own right because they've created a
67:33 substitute well take that now on
67:37 anthropomorphize a sex doll think about
67:42 it hopefully hopefully most people don't
67:45 have sex with their animal right the bay
67:47 area is actually packed with these
67:48 people the amount of stories I heard up
67:50 there about people who married someone
67:53 two stories two stories and twelve years
67:55 of a woman who married a guy and they're
68:00 married okay they've been one lady had
68:02 lived with her husband for like a year
68:04 and a half and came home and find him
68:06 having sex with his dog or dogs having
68:08 sex with him and and she's like freaking
68:12 out and they're right this is like I'm
68:13 two degrees from this person and he
68:18 screams and the dude says let him finish
68:21 oh yeah he's really well-adjusted human
68:26 being isn't he whatever reason he
68:30 substituted this dog for him and being
68:32 before he got married and then couldn't
68:35 let go of the relationship with his dog
68:37 okay
68:39 yikes so sex dolls think about it you
68:44 have something that looks like the kind
68:45 of person you want to be with it you
68:46 know 99.9% the time it's a guy because
68:50 we're programmed to procreate for our
68:52 entire lifetime sort of God they own
68:56 leaves you know these hot rubber dolls
68:58 you know it's always kind of weird about
69:03 to is that they don't actually as far as
69:05 I know I'm looking at the photos online
69:07 they don't look like
69:09 normal sized humans they look a little
69:11 smaller which is sort of a pedo twist to
69:13 it right mm-hmm
69:16 but you know right now most of them are
69:19 just just rubber dolls they just sit
69:22 there and do nothing but these guys have
69:25 taken them to dinners with other dudes
69:27 who have them they bring their
69:28 girlfriends some of these guys will
69:30 dress them up and take them into public
69:31 and stuff it's like I'm not trying to
69:33 slam these people but they're I mean we
69:39 have to redefine what mental health is
69:41 to look at this and go oh that's totally
69:43 good
69:43 that's totally agree now is a guy
69:45 hurting anybody I guess not as long as
69:47 he doesn't take it someplace else right
69:49 if he gets if it gets used to little
69:50 people and goes off to a playground goes
69:53 huh my god these move and they're warm
69:54 that might be a problem but now they're
69:57 trying to it's gonna take a while but
70:00 the trying to stuff a bunch a I into
70:02 these things so that they'd they a bunch
70:04 of talk to you I think right imagine
70:07 this thing starts talking to you and you
70:10 start thinking it's real there's a
70:12 Twilight Zone where a guy is given a
70:15 robot woman because he's on this
70:17 asteroid he's been he's in a he's been
70:19 sentenced to life on an asteroid and he
70:24 always has to have these three dudes
70:26 bring him his food every once in a while
70:28 because there's no food on the asteroid
70:30 it's just something that the military
70:32 does or whatever this group does and on
70:35 one of the visits he says look man it's
70:38 gonna be a little longer between
70:39 now in the next visit they're cutting
70:42 budgets and all this other stuff so I
70:44 brought you something special don't open
70:45 it until I leave the other guys don't
70:47 know what's in it don't say anything
70:49 so I get in the rocket ship and they
70:51 take off and the guy opens it up and
70:54 it's this beautiful woman she's actually
70:55 a supermodel in real life at the time
70:57 and she's very it was brilliantly
71:00 written I mean this just this is before
71:03 personal computers are in homes people
71:04 man this is like 20 years before this
71:06 ever happens right or at least 15 and
71:10 this is just before like basic
71:12 calculating computers not big computers
71:14 right but she gets out of the box and
71:18 she's very monotone and barely has any
71:20 emotions
71:21 and the guy you know he's really pissed
71:25 off that this thing is there cuz he's
71:27 like you're mocking me and you know this
71:29 is what they gave me this is ridiculous
71:31 I don't need this I need what I need is
71:32 a pardon I need to get off this rock you
71:33 know and he's just freaking out and he
71:35 eventually manhandles her and throws her
71:38 down like the first five minutes they're
71:40 together and she hits the ground and she
71:43 looks up at him and at tears coming out
71:45 of her eyes and he realizes oh my god
71:47 and I think she says something like I
71:50 have feelings too and as soon as she
71:53 said that she became human to him
71:55 the artificial intelligence started
71:57 adapting to him and she started becoming
71:59 more woman like and started figuring out
72:01 what he wanted wanted in the day does he
72:03 want coffee does he
72:04 you know eggs bacon or whatever she
72:07 totally assimilated him and he
72:11 immediately apologized to her and picks
72:14 her up and takes her inside her name was
72:17 Felicia I think it was her name and so
72:22 you know the time passes and eventually
72:25 these dudes come back and they're
72:28 running up to his house they're running
72:29 which is different than all their other
72:31 they usually hate the guy that I can
72:33 hear here you know the captain was
72:34 always a lot more tolerant but his other
72:36 two dudes were like screw you the guy
72:38 from Caddyshack was in it who owns the
72:40 golf course about 20 years before you
72:43 did catch egg but they show up and
72:46 they're like you got okay you've been
72:47 given the part and everyone's been given
72:49 pardons they you know this whole being
72:51 banished on an asteroid thing is being
72:53 shut down we're not coming back dude you
72:57 got to come with us and we got so many
72:58 dudes on the rocket that you're gonna
73:00 have to just bring the bare essentials
73:02 and he's like no problem man I'm just
73:04 gonna bring this this and this and
73:05 Felicia and the captain is like who's
73:09 Felicia oh my god it's the thing I gave
73:12 you last time I was here he was like
73:14 dude we don't have room for her I'm
73:16 really really sorry and he's like no
73:18 he's like what are you talking about he
73:19 goes I have to bring her she kept me
73:21 alive dude you know I mean she's like
73:23 been my everything she's my rock and
73:25 he's like sorry man
73:27 we can't he says we're gonna throw some
73:29 [ __ ] out you know this is dude we can't
73:31 do it and you got to get going we got to
73:33 get out of here our window to get out of
73:34 this place
73:35 is closing quickly because we're not
73:36 supposed to be here right now and so
73:39 he's like no she's real and he starts
73:42 running after cuz he told her to hide at
73:43 this particular place when they come and
73:46 he runs over to her and she's hiding in
73:47 these rocks and here comes the other
73:49 three dudes and he's like Felicia talk
73:51 tell him to show him that you're real
73:52 you know and she's all frozen which is
73:55 part of the writing suspension of
73:57 disbelief and the captain pulls out a
74:00 gun and shoots her in the face and blows
74:02 her face off and she's in some loop
74:06 saying something and he looks at the
74:09 other didn't go see she is really a
74:11 robot man she's not regal and he kind of
74:16 he wakes up he disengages and he's like
74:19 oh my god you're right your crowd I
74:20 can't believe I just you know totally
74:22 went there and so they get up and they
74:25 it's over he's okay but that gave us an
74:30 interesting perspective of what what
74:33 will happen to human beings if we start
74:35 replacing ourselves with human beings at
74:38 least robot look-alikes right now
74:41 technically speaking probably neither
74:42 you or me have anything against someone
74:46 being blessed to have a Felicia in their
74:48 life or whatever a Buck Rogers whatever
74:51 they want right it's their life they can
74:55 do what they want don't harm anybody and
74:58 and you're you're passing the test but
75:02 it would be interesting once
75:03 replicants became you know commonplace
75:07 take Blade Runner for instance man Daryl
75:11 Hannah my god I don't know if she's ever
75:14 been more beautiful in a movie than
75:15 playing pris and Blade Runner right even
75:18 splash was goofy it's you know as a you
75:23 know meat-eating male I'll just leave it
75:26 at that what I see here in that movie
75:28 you fantasize you fantasized in a split
75:31 second she's literally labeled in the
75:33 movie as a pleasure but your pleasure
75:36 model knows aura the other woman she's
75:39 also absolutely gorgeous but then she's
75:40 supposed to be Beauty and the Beast
75:42 she's a she'll kill you and she beats up
75:44 Deckard's character so it's easy to kind
75:46 of pull yourself away from that gonna
75:48 chick
75:49 I know some dudes that want to date
75:50 women like that I probably go for Priss
75:52 myself good now imagine you're 18 you're
75:57 18 to 22 in your mail and you you these
76:02 things are cheap and you get this robot
76:05 now you never have to deal with two
76:09 things one your family genes terminate
76:13 boom done because you're never gonna
76:15 find a woman why would you this woman
76:18 does everything that you could possibly
76:19 imagine every kinky thing you'd ever
76:21 want every little subservient thing you
76:23 want if you want her to stand up to you
76:25 probably just push a little button and
76:26 she starts getting honor with you right
76:29 but - if you don't deal with conflict
76:34 with another human being especially the
76:36 feminine or male masculine side the
76:39 other side of the equation well there's
76:41 a whole hell of a lot of development
76:42 that never happens in you but you still
76:45 have to go out in the real world and
76:47 deal with society and so imagine like
76:51 200 years ago women in most places in
76:56 the world
76:56 okay Hawaii's a little bit different
76:58 where he had them what is it the
77:01 patriarchy rate women were super
77:05 subservient they were beat down for
77:07 thousands of years you don't say nuttin
77:09 right you know and if certain Sharia law
77:11 world's take president's precedence as
77:16 they do in Great Britain Great Britain
77:18 has communities that have their own
77:20 Sharia law courts right and so women are
77:23 just nothing in those courts men nothing
77:26 there's all kinds of legal ways you can
77:28 kill your wife and all kinds of wild
77:29 stuff right so you get a robot that's
77:33 now obeying everything that you want on
77:35 the opposite sex side now your
77:36 perception of the opposite sex is all
77:38 screwed up maybe your perception
77:41 humanity's screwed up
77:42 why are you disagreeing with me do what
77:44 I say you you like take a male they
77:47 would have with these robots at home
77:48 doing everything the guy once and I mean
77:50 physically mentally everything right he
77:54 wants for nothing constantly okay you
77:56 might think well great we'll have a nice
77:57 happy male in the world hmm
77:59 then he gets a female boss
78:01 and she's busting his balls cuz maybe
78:03 he's messing up her work maybe he's
78:05 being sexist because at home he just has
78:08 to say I want to do this and she's
78:10 already in the position and nude and
78:12 ready to do it and the guy gets all
78:14 screwed up in his head and now the
78:16 woman's got a discipline him but he
78:19 doesn't know how to take orders from a
78:20 woman
78:20 because at home that didn't happen and
78:23 that's sort of something we're breaking
78:25 through right now and trying to get you
78:27 know some of these Neanderthal women
78:30 excusing and oath all men excuse me
78:32 ladies to treat women normally I mean
78:35 this stuff you know it's it's still in
78:38 it still I'll put it this way I think
78:42 that it is in a very small percentage of
78:45 society of men who do this very small I
78:48 don't even want to quote a percentage
78:50 because I don't know but the ones that
78:53 are bad are really bad and they scar
78:55 women with their antics with the things
78:58 that they expect from women things
78:59 they'll do behind closed doors things
79:01 they say out of their mouths it's really
79:03 bad and the scenarios I'm talking about
79:06 are my female friends that tell me that
79:07 their bosses have done atrocious things
79:10 in rooms mention things that are wholly
79:15 inappropriate but they're unable to to
79:17 throw down because these men are at the
79:20 tippy top of these big companies I mean
79:23 like big giant corporations that have
79:26 you know a global presence and what are
79:31 you gonna do this guy's got more money
79:33 than you he's got more power than you
79:35 well we might say he's sorry on Monday
79:38 if you say some to HR but he's gonna
79:40 have it out for you from that day on
79:43 you'll either be promoted until your
79:46 failed or you'll be transferred demoted
79:49 or something something's gonna happen to
79:52 you you're gonna lose that opportunity
79:53 because you said something about being
79:55 treated right it's happening it is
79:57 happening as much as men don't want to
79:59 admit it because like it's easy for me
80:02 to say I've never been like that to
80:03 another woman in my life
80:04 I mean I think that's I was raised
80:06 completely different chivalry was the
80:08 name of the game when I was being raised
80:10 right but so I might well I might be
80:14 cavalier about how men
80:15 don't do that and then I hear these
80:16 stories and it's almost hard to believe
80:18 some of these stories that's the other
80:19 thing you don't admit like no way I know
80:23 the chicks like yeah totally and it'll
80:26 be another woman right next to her going
80:27 yeah that's happened to me too and
80:29 you're just like oh my god we're still
80:31 broken
80:32 so in closing this thing off we have a
80:37 bit of a dilemma artificial intelligence
80:41 is something that governments are
80:44 programming behind closed doors military
80:46 it's being programmed at every every
80:50 level of law enforcement with the notion
80:53 of trying to get people to behave better
80:55 or predict who's gonna lose their mind
80:57 and try to shoot up someplace right it's
81:00 being used to really turn the screws on
81:03 you with some of the laws that maybe
81:05 don't have or maybe they have loopholes
81:07 or something and this these AIS are
81:09 trying to figure out where you're taking
81:10 advantage of things you know we have
81:13 speed limits in the world don't we in
81:16 most countries and as much as we have
81:19 them the only a handful of people really
81:21 sit there you know looking at their
81:23 speedometer those I'm young kids do it
81:25 but all your folks are like yeah
81:26 whatever
81:27 and we like that we like that little bit
81:29 of flexibility with reality you know
81:34 business is the deal in pure cash Wow
81:36 when it comes time to reporting your
81:38 income it's it's it's an honor system
81:43 right so what are the other places that
81:47 are developing AI well you've got
81:49 universities a lot of universities I
81:51 think a lot of you know this maybe some
81:53 of you don't they're tied into military
81:56 that's how they can make a tremendous
81:58 amount of money with their research some
82:01 universities are just like their
82:04 proverbial technical condoms for
82:06 military everything they do is sold
82:09 straight to the military like I said I
82:14 had a friend of mine in the video game
82:16 business 25 years ago who shared with me
82:19 that you know he developed a bacteria
82:23 eating virus and
82:28 his prefer it was an extra credit
82:30 question as PhD test and he was able to
82:33 take it home and he created this whole
82:35 thing how to synthesize that how to make
82:36 it and this was in the earlier 90s
82:39 before he this is when he actually did
82:41 it was in the earlier 90s and he said
82:43 that his professor came to him from the
82:44 college and said do you mind if I sell
82:47 this answer to the military they're
82:50 willing to build a new wing on the side
82:51 of the college and he said sure and then
82:55 within two years someone in Canada died
82:59 of this exact thing and now it's all
83:02 over the press right all these people
83:03 dying these bacterial skin eating
83:06 viruses and stuff people go in the water
83:08 and get it and where they get it
83:09 someplace no one knows where they
83:11 actually get it he was very fearful that
83:15 someone just took it across the border
83:17 and tested it so that can be a little
83:20 freaky right artificial intelligence can
83:23 also be something a nerd does in his
83:27 basement it's possible and you have to
83:31 understand with technology and all
83:33 skills in life you know this for a fact
83:35 you you have one at least one in your
83:38 life you do where there's something that
83:41 you learned how to do at some probably
83:44 earlier stage in your life but doesn't
83:45 always have to be and for whatever
83:47 reason it was super easy for you and
83:50 it's hard for everybody else I was
83:52 really good in geometry and [ __ ]
83:54 trigonometry all my friends were either
83:57 passing with a grades or failing with F
83:59 pluses it was either their brain thought
84:02 that way or didn't think that way some
84:05 people really good at calculus
84:08 other arts but some people could play
84:11 the piano some people can play sports
84:12 and some people can program inside
84:16 programming there's all kinds of
84:17 different programming category straiten
84:19 so you have like your your most novice
84:21 coder in the world is your web coder
84:23 your next level up may be like a mobile
84:25 code or an application programmer your
84:28 next level up would be your video game
84:30 programmer next level up from that would
84:34 be your artificial intelligence
84:35 programmer I guess the video game
84:37 business is a nice just throw that in
84:40 there class ii here it's a nice place
84:41 two distinct
84:42 which between true AI and just really
84:46 smart systematic algorithms okay there's
84:49 one could say they're both the same
84:51 thing but I don't think it is
84:52 for instance first-person shooters for a
84:56 long time had to be networked video
85:00 games where you had to play another
85:01 human being because they didn't have the
85:03 artificial intelligence quote-unquote as
85:08 advances that needed to be to build an
85:10 opponent that was artificial that would
85:12 come and get you and then as we got
85:14 better and better at that boy that a I
85:16 started getting insane but it's not
85:19 really learning anything that's the
85:22 thing it simply looks at where you are
85:25 in the map and comes after you that's it
85:28 that's not what I would call artificial
85:31 intelligence the robot driving down your
85:34 street is not necessarily AI in my
85:39 opinion
85:40 Phylicia the robot that's AI that's
85:43 someone learning all kinds of
85:44 metaphysical reactions to emotions be
85:48 able to cry able to laugh knowing when a
85:51 joke is funny would be the most
85:53 incredible AI in the world they're you
85:56 know they said that it came out recently
85:59 that they had an AI write a screenplay I
86:02 would love to read that would be
86:04 probably some pretty dry [ __ ] or the
86:08 programmers of the AI simply filled it
86:10 with a catalogue of all jokes and all
86:12 gags and all methodologies to make
86:15 suspense happen and all the algorithm is
86:17 doing is just stitching something
86:19 together that's mildly believable where
86:21 locations are managed and characters are
86:23 managed and there's Anna tagging ass
86:25 Brenda protagonist antagonist going
86:28 after each other okay is that really a I
86:32 mean as a computer able to go I'm gonna
86:34 think of a new futuristic movie were you
86:37 know a cop comes from the future goes to
86:39 the past and tries to kill Sarah Connors
86:41 that would be true AI if it's not biting
86:44 it off of another script that's been fed
86:46 to it if an AI could write a piece of
86:49 poetry that really touched the soul
86:52 where you didn't see other people's
86:54 poetry
86:55 lifted and just simply rephrased it's
86:59 truly original work that would be AI so
87:04 what I'm trying to do with this episode
87:06 is to focus you on areas one to
87:08 establish the distinction between the
87:10 two both can be very formidable right
87:13 algorithms can be just as deadly as true
87:15 artificial intelligence that can learn
87:17 you're probably more threatened
87:21 technically speaking by an algorithm
87:23 they can't learn then an algorithm that
87:26 could learn right so you could you know
87:30 all these sci-fi movies where they take
87:31 robots and/or sort of Hal 9000 sort of
87:35 things how never had a body you just had
87:37 a lie ball right you got all the
87:38 eyeballs on the whole place but if you
87:42 say the say a robot wanted to hurt you
87:44 and then you could have a conversation
87:47 with it and say well I don't think you
87:49 want to hurt me well why wouldn't I want
87:50 to hurt you you know and then you can
87:51 have the conversation and teach it the
87:54 value of life beyond its own personal
87:56 boot-up definition that would be an AI
87:59 but if the goddamn thing is just a robot
88:02 with an algorithm to kill there's no
88:05 conversation there's no learning it is
88:08 there you are human you are to die
88:10 there's no input for any other
88:12 eventualities that's more dangerous than
88:15 artificial intelligence that already
88:18 exists and that's existed for a really
88:21 long time and we're all still alive the
88:24 social ramifications of replacing human
88:26 beings with artificial ones oof
88:29 I think the nanny to help raise your
88:33 kids if we could ever build a machine
88:34 that we would trust in such a way maybe
88:37 maybe I wouldn't start with kids right
88:39 once you put one in my house to help me
88:42 clean up and do my laundry then we'll
88:45 move on to other avenues right what I
88:49 don't want to see personally is a
88:51 misunderstanding of the technology that
88:53 leads to hysteria that we can't manage I
88:56 don't know if it can be done in this
88:58 particular category because of the
89:01 infinite combinations that can be
89:03 created behind our back and it's it's
89:06 almost as if society has to remain
89:08 vigilant about
89:09 where this technology is being taken
89:11 into what extent and what try to what
89:13 excuse me what problems were trying to
89:17 solve with it but I you know what's
89:20 funny about it is or interesting I
89:22 should say is that we are not having a
89:26 global conversation at all about this
89:28 and partially it's because of the
89:30 misunderstanding of what it is and where
89:34 would you go where would you go to have
89:36 a real dialogue I mean isn't this kind
89:39 of interesting about the world right now
89:41 we have this internet it's you know
89:45 being used 90% by the deep state to
89:48 control our thinking 10% to pass around
89:51 the truth but even the truth is hard to
89:54 discern today because they've realized
89:56 they can infect those arteries with this
89:57 information and so genes what do you
89:59 know it's true or false right we as far
90:04 as I know beside think tanks which
90:07 usually have a very strict definition of
90:11 what you're going there for cuz a think
90:13 tank requires usually it's usually meets
90:15 on a particular day of the week a lot of
90:17 times that meets on weekends because
90:19 everyone's off on the weekend some of
90:21 them have to charge money because they
90:22 have to pay for the lights and the venue
90:24 that you're going to but you're there to
90:26 usually make money because you're
90:29 spending money to be there and so you're
90:32 really dealing usually with business
90:33 objectives now once you deal with
90:36 government departments that that's where
90:39 you start getting into a group that does
90:41 analysis on things what if we had a
90:44 terrorist attack what if a nuclear bomb
90:45 map and what if they have a massive
90:47 earthquake two massive earthquakes what
90:48 if a meteorite lands in Colorado what a
90:52 field of stone explodes you know all
90:54 these different things what if aliens
90:56 landed on earth you know I mean all
90:57 these different scenarios that's where
90:59 your government spends money lots of
91:02 money and thinks about these things now
91:05 that's not necessarily a bad thing but
91:09 shouldn't we as the citizens the 99% of
91:12 the rest of the world be having some
91:14 sort of intelligent dialogue about this
91:16 stuff I mean part of its why I create
91:20 all these weird esoteric episodes so
91:22 maybe my little drop in the bucket and
91:25 my drop in the ocean can can influence
91:27 something to have a conversation again
91:31 it's not important that I'm right or
91:32 wrong about anything I've ever talked
91:34 about any on any of the episodes what's
91:36 most important is you think that'll
91:38 bring up subjects that makes you either
91:40 disagree or agree because you're either
91:41 affirming your own beliefs that are
91:43 contrary to my own or maybe you've never
91:45 thought about it before and it
91:47 introduces itself as oh my gosh yeah I
91:49 probably should put some cellular power
91:51 into this thought into this
91:53 eventualities for mankind so I'll tell
91:57 you this
91:57 at the end of this thing if anyone else
92:01 comes back out to the press and says
92:02 I've seen something that terrifies me
92:05 about the world of AI blah blah blah if
92:08 the next thing out of their mouth isn't
92:10 what they saw be suspicious of that
92:15 person and be disappointed in that
92:17 person because they're not telling you
92:20 what's going on you know it would be
92:23 tantamount to someone saying we finally
92:28 talked to aliens they came down in area
92:30 51 had a conversation with us and it was
92:33 terrifying it's like okay well if you're
92:37 going to make me terrified to go to
92:38 sleep now and you know worried about an
92:40 alien invasion will you at least owe it
92:42 to me either to do one or two things
92:44 keep it to yourself because it's
92:46 something we can control or we learn how
92:51 to duck and cover from aliens or
92:52 something right we're here to preserve
92:55 mankind that's what we are if we do
92:59 anything to undermine mankind if you buy
93:02 into this hate humanity thing which is a
93:05 big theme going on it's been going on
93:06 forever then I don't know I don't know
93:11 what your position in the world or your
93:13 value of to the world is if you're sort
93:16 of subliminally a psychopath that wants
93:18 to get rid of the world you know they
93:20 want to watch the world burn as we
93:21 talked about in many episodes I hope you
93:25 hope that person don't accuse anybody
93:28 watching the show I hope that person can
93:30 find a way to recalculate their
93:33 perception of the world yeah there's a
93:36 lot
93:36 people that are different than every
93:37 single one of us and it frustrates us
93:39 that they're in a stage in their life
93:42 right now where it seems like they're
93:44 completely delusional
93:45 we've been through phases like this in
93:47 the past segregation or desegregation in
93:51 the 60s where blacks weren't allowed to
93:53 go to schools with whites and we had
93:55 separate fountains and separate
93:56 bathrooms and all this other stuff that
93:58 was a atrocious era of America and we
94:04 grew out of it thank God now we still
94:07 have people that are believed that that
94:08 should be the way it is sure but they're
94:10 very isolated they're very teeny tiny in
94:12 number and they're not getting their way
94:13 that's the nice thing right and so when
94:18 we contemplate replacing you know human
94:21 functionality with artificial
94:23 functionality just remember just like
94:26 your brain when you take a drug all the
94:29 time that supplies let's say dopamine to
94:32 your body or testosterone or some other
94:36 thing that you're taking your body stops
94:38 manufacturing it because your body says
94:40 I don't need to your body only makes
94:43 what it needs to it feels the
94:45 deprivation and your body and goes make
94:47 this because we're gonna die if we don't
94:48 make it
94:48 if you habitually take a drug then your
94:52 body can lose all functionality to ever
94:53 turn it back on
94:54 that's why certain eating habits are
94:57 really bad for you when you stop eating
94:58 what you're made out of your body stops
95:01 trying to find it from food supplies and
95:04 it signs it by eating you alive while
95:07 your skin gets really thin and and you
95:09 get sick and you croak 20 30 40 years
95:13 before you're supposed to teach their
95:16 own for sure but I think artificial
95:18 intelligence is aimed at the world as a
95:22 whole not just an individual so
95:25 something that we have to kind of keep
95:27 our eyes open on if any of you follow
95:29 this particular division of science this
95:34 is something that turns you on and you
95:36 actively seek out arteries and if you've
95:39 ever found any really good arteries that
95:41 update on a daily basis please share
95:44 them down below for me personally
95:45 because I'd like to find some decent
95:47 arteries because I don't
95:49 I don't know of any really good you know
95:53 sort of Internet junctions where this
95:57 stuff is barked out on a daily basis and
95:59 I can't say it I've done the tremendous
96:01 amount of research trying to find that
96:02 sort of thing but I would like to get it
96:05 from a person who really has this as a
96:07 pet project of their own because I think
96:10 you will have already done the sifting
96:11 for me so that'd be cool I'm going to
96:14 guess that almost no one will ever post
96:17 that because I don't think anyone ever
96:18 follows it but if you do please please
96:20 share it down below I hope you feel me
96:24 and on the subject of sharing if you
96:27 haven't been to deep thoughts radio.com
96:28 please go we have currently as of this
96:31 recording two feeds for a video which is
96:33 YouTube and bit shoot but shoot has been
96:36 really great they're a little it's a
96:39 little ornery to upload videos but I
96:41 think the Lord that they exist let's put
96:44 that way as far as audio you can have it
96:46 on your Mac or your Android device
96:48 iPhone Android whatever you want links
96:51 are all on the website there's two
96:53 social media outlets Twitter which I
96:55 just post you know the videos when they
96:58 show up I don't like Twitter at all I
97:00 don't mess around with it at all
97:01 and then the lochs Facebook group so
97:04 it's a private place it's locked and so
97:07 we have just a great group of folks it's
97:09 a good place to just have a laugh I mean
97:12 what's great I could just tell you
97:14 personally I go up there to have my day
97:16 uplifted and just by everybody all their
97:19 comments and and kind of some of the
97:21 chaotic responses or posts that people
97:23 have it's great so thanks to both Kaz
97:27 and Dave for moderating that with me
97:29 really appreciate that with funding the
97:35 show there's definitely two places to
97:37 donate there's a PayPal account which no
97:39 one's ever used and there's the patreon
97:41 which a lot of social media outlets do
97:43 for those of you concerned about anyone
97:46 generating revenue off something like
97:47 this and still being not a shill and all
97:50 that conversation I put ads on some of
97:53 the videos I put banner ads on
97:54 everything but some of the videos where
97:56 I think all of the diehards have already
97:58 seen it I turn on a pre-roll ad that you
98:00 can skip the reason for all this
98:02 fundraising again
98:03 most I've ever made in a month was I
98:06 think 160 bucks
98:08 that's when patreon was really high and
98:09 my view count was really really high so
98:12 knock yourself I mean I'm not making a
98:14 ton of cash off this each stick is about
98:16 ten bucks so think about that but the
98:20 real goal would be to obviously
98:22 supplement my income to a point where I
98:24 could do this at a much higher level of
98:27 quality and potentially hire other
98:29 people to help put together the show and
98:32 produce episodes for me such that I have
98:34 more data than I would ever find by
98:36 myself but you know I would love to get
98:38 out of the editing process which is a
98:40 super time consumer if I'm ever taking
98:43 time to put up a so down usually I've
98:46 got five or six in the queue like right
98:48 now I have about eight in the queue that
98:50 none of them are released yet I'm gonna
98:51 have to go through and pound through all
98:53 these episodes I've done three episodes
98:55 I've thrown away just this just this the
99:00 season before it's launched like this is
99:02 season five right now but I haven't even
99:04 launched season five as a result of I
99:05 mean as at the point I'm working on the
99:07 intro right now so the reason why I
99:09 pisode to get thrown away is because
99:11 they suck and why do they suck because I
99:13 don't have enough time to really
99:14 research things properly when I watch a
99:16 bag or listen to it or think about him
99:17 like a naps trash so that's that's the
99:22 reason for funding this thing and
99:23 getting it to blow up it probably never
99:25 will it's SuperDuper shadow band so
99:27 whatever right and as I always say
99:31 there's a remastered season one which
99:33 I'll probably stop saying about halfway
99:35 through season five if you see anything
99:37 on this channel and season one that's
99:40 the original version of the show
99:42 sometimes they play sometimes they don't
99:44 because they have music in them that's
99:45 copyrighted I took all that out for the
99:48 new season one rebalanced all the audio
99:49 took out a bunch of pauses again some
99:51 episodes are five minutes shorter
99:53 because of all the stuff that's been
99:54 taken out not in other words but just
99:58 just pauses and stuff so anyway until
100:02 the next episode take care of yourself
100:04 and someone else and I'll see in the
100:05 next deep thoughts over now
100:09 [Applause]
100:13 [Music]
100:16 [Applause]
100:26 [Music]
100:32 [Music]